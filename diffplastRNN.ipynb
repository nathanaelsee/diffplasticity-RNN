{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "diffplastRNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathanaelsee/diffplasticity-RNN/blob/master/diffplastRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9iqFvKNk4H-p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extension of Uber's Differentiable Plasticity:\n",
        "https://github.com/uber-research/differentiable-plasticity/\n",
        "\n",
        "##Examples/tutorials used:\n",
        "\n",
        "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html  \n",
        "https://jovianlin.io/pytorch-with-gpu-in-google-colab/  "
      ]
    },
    {
      "metadata": {
        "id": "-SmJrhTsGo4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Check Python version and GPU"
      ]
    },
    {
      "metadata": {
        "id": "ed-8FUn2GqQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.version\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUdrKNcTHaqe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "UrlaSAp1Gt6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vxgCzP8pHqYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "tqgh6bI9HgiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f7baa5b1-795c-4506-f085-cf6d27d4f269"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA version:\\t\", torch.version.cuda)\n",
        "print(\"cuDNN version:\\t\", torch.backends.cudnn.version())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 0.4.1\n",
            "CUDA version:\t 9.2.148\n",
            "cuDNN version:\t 7104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1wrQjc-Vfr-z"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Dataset\n",
        "\n",
        "Dataset of names and their lingustic backgrounds taken from https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html"
      ]
    },
    {
      "metadata": {
        "id": "9qZFluUHlqTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0uP08SCoAlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1bdfb891-a1cd-4e53-e23c-08f4e3227c19"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print('Ślusàrski ->', unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "\n",
        "print(all_categories)\n",
        "print(category_lines['Italian'][:5])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ślusàrski -> Slusarski\n",
            "['Irish', 'French', 'Arabic', 'Polish', 'German', 'Korean', 'Portuguese', 'Scottish', 'Greek', 'Vietnamese', 'Spanish', 'Czech', 'Russian', 'Dutch', 'Chinese', 'English', 'Japanese', 'Italian']\n",
            "['Abandonato', 'Abatangelo', 'Abatantuono', 'Abate', 'Abategiovanni']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4hgCecJDIi8o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the model\n",
        "\n",
        "Credits to Uber: https://github.com/uber-research/differentiable-plasticity/  \n",
        "Modifications made to original sample code."
      ]
    },
    {
      "metadata": {
        "id": "QQK4vsUchWCg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DiffPlastRNN(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        \n",
        "        super(DiffPlastRNN, self).__init__()\n",
        "        self.input_size  = input_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        # Initialize trainable parameters\n",
        "        self.w     = nn.Parameter(.01 * torch.randn(input_size, output_size), requires_grad=True) # The matrix of fixed (baseline) weights\n",
        "        self.alpha = nn.Parameter(.01 * torch.randn(input_size, output_size), requires_grad=True) # The matrix of plasticity coefficients\n",
        "        self.eta   = nn.Parameter(.01 * torch.ones(1),                        requires_grad=True) # The \"learning rate\" of plasticity\n",
        "\n",
        "    # Run the network for one timestep\n",
        "    def forward(self, input, yin, hebb):\n",
        "        \n",
        "        # using tanh as non-linearity, as per Uber's implementation\n",
        "        yout = F.tanh( yin.mm(self.w + torch.mul(self.alpha, hebb)) + input )\n",
        "        \n",
        "        # Oja's rule. yin, yout are row vectors (dim (1,N))\n",
        "        hebb = hebb + self.eta * torch.mul((yin.unsqueeze(1) - torch.mul(hebb , yout.unsqueeze(0))) , yout.unsqueeze(0))\n",
        "        \n",
        "        return yout, hebb\n",
        "\n",
        "    # Return an initialized, all-zero hidden state\n",
        "    def initialZeroState(self):\n",
        "        return torch.zeros(1, self.input_size)\n",
        "\n",
        "    # Return an initialized, all-zero Hebbian trace\n",
        "    def initialZeroHebb(self):\n",
        "        return torch.zeros(self.input_size, self.output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xvLScxMxI0_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "net = DiffPlastRNN(n_letters, n_categories)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYBesVm1I4yf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Enable GPU\n",
        "\n",
        "_**Note**: You could enable this line to run the codes on GPU_"
      ]
    },
    {
      "metadata": {
        "id": "oQ6isf-kI2HD",
        "colab_type": "code",
        "outputId": "7a40e5ab-47b1-48e9-c045-f29be2fb59d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_cuda = True\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "    print(\"Using CUDA!\")\n",
        "else:\n",
        "    net.cpu()\n",
        "    print(\"Using CPU!\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2CUPz-X84j5m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialize Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "Jo60XGznI_Ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "n_letters = len(all_letters)\n",
        "n_categories = len(all_categories)\n",
        "learning-rate = 1e-6\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T0N8trAe4tmj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "below is sample code from original tutorial, ignore"
      ]
    },
    {
      "metadata": {
        "id": "VLUaX6tuJMQi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training the FNN Model\n",
        "\n",
        "This process might take around 3 to 5 minutes depending on your machine. The detailed explanations are listed as comments (#) in the following codes."
      ]
    },
    {
      "metadata": {
        "id": "qBrGa7qMJKcB",
        "colab_type": "code",
        "outputId": "1e9208fb-bba4-41a5-a620-a08e5150a8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
        "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
        "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
        "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
        "        loss.backward()                                   # Backward pass: compute the weight\n",
        "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
        "        \n",
        "        if (i+1) % 100 == 0:                              # Logging\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.3270\n",
            "Epoch [1/5], Step [200/600], Loss: 0.2756\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2773\n",
            "Epoch [1/5], Step [400/600], Loss: 0.1931\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1273\n",
            "Epoch [1/5], Step [600/600], Loss: 0.2067\n",
            "Epoch [2/5], Step [100/600], Loss: 0.1348\n",
            "Epoch [2/5], Step [200/600], Loss: 0.1073\n",
            "Epoch [2/5], Step [300/600], Loss: 0.1898\n",
            "Epoch [2/5], Step [400/600], Loss: 0.1743\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0714\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0631\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0785\n",
            "Epoch [3/5], Step [200/600], Loss: 0.1645\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0878\n",
            "Epoch [3/5], Step [400/600], Loss: 0.1399\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0438\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0766\n",
            "Epoch [4/5], Step [100/600], Loss: 0.1236\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0239\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0508\n",
            "Epoch [4/5], Step [400/600], Loss: 0.1045\n",
            "Epoch [4/5], Step [500/600], Loss: 0.1045\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0472\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0121\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0696\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0398\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0211\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0468\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0381\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lhOeVK6RKz1-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing the FNN Model\n",
        "\n",
        "Similar to training the neural network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
        "\n",
        "1. No loss & weights calculation\n",
        "2. No wights update\n",
        "3. Has correct prediction calculation\n"
      ]
    },
    {
      "metadata": {
        "id": "0ue19srtK4C1",
        "colab_type": "code",
        "outputId": "0816eee6-aba7-42be-f2b8-7221a8a96bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_loader:\n",
        "    images = Variable(images.view(-1, 28*28))\n",
        "    \n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "    \n",
        "    \n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "    total += labels.size(0)                    # Increment the total count\n",
        "    correct += (predicted == labels).sum()     # Increment the correct count\n",
        "    \n",
        "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10K test images: 97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EM7EnBoyK8nR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the trained FNN Model for future use\n",
        "\n",
        "We save the trained model as a pickle that can be loaded and used later."
      ]
    },
    {
      "metadata": {
        "id": "uof2bcfIK5n7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'fnn_model.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}